{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import islice\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T10:32:44.709120Z",
     "iopub.status.busy": "2022-05-19T10:32:44.708564Z",
     "iopub.status.idle": "2022-05-19T10:32:45.176612Z",
     "shell.execute_reply": "2022-05-19T10:32:45.175930Z",
     "shell.execute_reply.started": "2022-05-19T10:32:44.709064Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T10:32:40.154676Z",
     "iopub.status.busy": "2022-05-19T10:32:40.154063Z",
     "iopub.status.idle": "2022-05-19T10:32:40.993064Z",
     "shell.execute_reply": "2022-05-19T10:32:40.992369Z",
     "shell.execute_reply.started": "2022-05-19T10:32:40.154620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code running in a notebook, loading display tools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.streams import document_stream, stream_cleaned_texts, reservoir_sample, get_porn_domains, stream_all_records\n",
    "from utils.topic import create_topic_model, PornClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/work/netarkivet-cleaned/\"\n",
    "SAVE_PATH = \"/work/topic_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"nmf\"\n",
    "N_TOPICS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T10:32:48.013089Z",
     "iopub.status.busy": "2022-05-19T10:32:48.012540Z",
     "iopub.status.idle": "2022-05-19T10:32:48.061432Z",
     "shell.execute_reply": "2022-05-19T10:32:48.060618Z",
     "shell.execute_reply.started": "2022-05-19T10:32:48.013034Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = stream_cleaned_texts(data_path=DATA_PATH, filter_porn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T10:41:07.007266Z",
     "iopub.status.busy": "2022-05-19T10:41:07.006777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#I don't know what the optimal number of workers is, try different things and see what works best\n",
    "#2 tends to be okay.\n",
    "documents = document_stream(texts, workers=2)\n",
    "#Randomly sample 100_000 documents  from the first 5 million\n",
    "#This way we can be sure that all topics are included,\n",
    "#but we won't have to use as much memory\n",
    "documents = islice(documents, 5_000_000)\n",
    "documents = reservoir_sample(documents, 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, matrix, vectorizer = create_topic_model(\n",
    "    documents,\n",
    "    model_type=MODEL_TYPE,\n",
    "    n_topics=N_TOPICS,\n",
    "    max_freq=0.3,\n",
    "    max_vocab=15_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Display topic model\n",
    "pyLDAvis.sklearn.prepare(model, matrix, vectorizer, sort_topics=False)\n",
    "#sot_topics is important as otherwise it displays topics in a messed up order\n",
    "#Which doesn't correspond to the actual features at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, os.path.join(SAVE_PATH, f\"{MODEL_TYPE}_{N_TOPICS}.joblib\"))\n",
    "joblib.dump(vectorizer, os.path.join(SAVE_PATH, f\"tf-idf_{MODEL_TYPE}_{N_TOPICS}.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the topic model for porn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_domains = get_porn_domains(DATA_PATH)\n",
    "#obtain a sample of records\n",
    "SAMPLE_SIZE = 200_000\n",
    "records = stream_all_records(DATA_PATH)\n",
    "records = islice(records, 5_000_000)\n",
    "sample = reservoir_sample(records, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, is_porn = np.zeros(shape=SAMPLE_SIZE), np.zeros(shape=SAMPLE_SIZE)\n",
    "for i, record in enumerate(records):\n",
    "    texts[i] = record[\"text\"]\n",
    "    is_porn[i] = record[\"domain_key\"] in porn_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = PornClassifier.load(f\"{MODEL_TYPE}_{N_TOPICS}\")\n",
    "predictions = classifier.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(is_porn, predictions))\n",
    "print(precision_score(is_porn, predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
